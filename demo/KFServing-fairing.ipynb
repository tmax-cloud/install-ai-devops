{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap \"docker-config\" deleted\n",
      "configmap/docker-config created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 211118 06:15:45 cluster:46] Building image using cluster builder.\n",
      "[I 211118 06:15:45 base:107] Creating docker context: /tmp/fairing_context_dog63kd2\n",
      "[I 211118 06:15:45 converted_notebook:127] Converting KFServing-fairing.ipynb to KFServing-fairing.py\n",
      "[W 211118 06:15:45 manager:298] Waiting for fairing-builder-sp6rt-srsj6 to start...\n",
      "[W 211118 06:15:46 manager:298] Waiting for fairing-builder-sp6rt-srsj6 to start...\n",
      "[W 211118 06:15:46 manager:298] Waiting for fairing-builder-sp6rt-srsj6 to start...\n",
      "[W 211118 06:15:46 manager:298] Waiting for fairing-builder-sp6rt-srsj6 to start...\n",
      "[I 211118 06:15:46 manager:304] Pod started running True\n",
      "[I 211118 06:15:47 manager:304] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mINFO\u001b[0m[0004] Retrieving image manifest kitaeyoo777/kubeflow-kfserving:test6\n",
      "\u001b[36mINFO\u001b[0m[0006] Retrieving image manifest kitaeyoo777/kubeflow-kfserving:test6\n",
      "\u001b[36mINFO\u001b[0m[0008] Built cross stage deps: map[]\n",
      "\u001b[36mINFO\u001b[0m[0008] Retrieving image manifest kitaeyoo777/kubeflow-kfserving:test6\n",
      "\u001b[36mINFO\u001b[0m[0009] Retrieving image manifest kitaeyoo777/kubeflow-kfserving:test6\n",
      "\u001b[36mINFO\u001b[0m[0011] Executing 0 build triggers\n",
      "\u001b[36mINFO\u001b[0m[0011] Unpacking rootfs as cmd RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi requires it.\n"
     ]
    }
   ],
   "source": [
    "from kubernetes import client\n",
    "\n",
    "\n",
    "from kfserving import constants\n",
    "from kfserving import KFServingClient\n",
    "from kfserving import V1beta1PredictorSpec\n",
    "from kfserving import V1beta1InferenceService\n",
    "from kfserving import V1beta1InferenceServiceSpec\n",
    "from kfserving import V1beta1TFServingSpec\n",
    "from kfserving import utils\n",
    "\n",
    "\n",
    "from kubernetes.client import V1ResourceRequirements\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "## kfserving module을 이용해 python code로 직접 클러스터에 serving을 하는 과정\n",
    "class KFServing(object):\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--namespace', required=False, default='kubeflow')\n",
    "        parser.add_argument('--storage_uri', required=False, default='/mnt/export')\n",
    "        parser.add_argument('--name', required=False, default='kfserving-sample')        \n",
    "        args = parser.parse_args()\n",
    "        namespace = args.namespace\n",
    "        serving_name =  args.name\n",
    "        api_version = constants.KFSERVING_GROUP + '/' + constants.KFSERVING_V1BETA1\n",
    "                                      \n",
    "        \n",
    "        ## inference server spec 정의\n",
    "        predictor=V1beta1PredictorSpec(tensorflow=V1beta1TFServingSpec(\n",
    "                                      storage_uri=args.storage_uri,\n",
    "                                      resources=V1ResourceRequirements(\n",
    "                                          requests={'cpu':'100m','memory':'1Gi'},\n",
    "                                          limits={'cpu':'100m', 'memory':'1Gi'})))\n",
    "        \n",
    "        \n",
    "        ## kfserving crd(inferenceservice) 정의       \n",
    "        \n",
    "        isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                   kind=constants.KFSERVING_KIND,\n",
    "                                   metadata=client.V1ObjectMeta(\n",
    "                                       name=serving_name, namespace=namespace),\n",
    "                                   spec=V1beta1InferenceServiceSpec(predictor=predictor))\n",
    "        \n",
    "        KFServing = KFServingClient()\n",
    "        \n",
    "        \n",
    "        KFServing.create(isvc)\n",
    "        print('waiting 5 sec for Creating InferenceService')\n",
    "        time.sleep(5)\n",
    "        \n",
    "        KFServing.get(serving_name, namespace=namespace, watch=True, timeout_seconds=300)\n",
    "\n",
    "## serving하는 python 코드를 fairing으로 imaging 하는 작업\n",
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:      \n",
    "        from kubeflow import fairing\n",
    "        from kubeflow.fairing.kubernetes import utils as k8s_utils        \n",
    "        from kubeflow.fairing.builders.cluster.cluster import ClusterBuilder\n",
    "        from kubeflow.fairing.builders.cluster.minio_context import MinioContextSource\n",
    "        from kubeflow.fairing.preprocessors.converted_notebook import ConvertNotebookPreprocessor\n",
    "        \n",
    "        ## 이미지를 배포하기 위한 auth정보 등록\n",
    "        ! kubectl delete cm docker-config\n",
    "        ! kubectl create cm docker-config --from-file=/home/jovyan/.docker/config.json\n",
    "\n",
    "        DOCKER_REGISTRY = 'kitaeyoo777'\n",
    "        base_image = 'kitaeyoo777/kubeflow-kfserving:test6'\n",
    "        image_name = 'kfserving'\n",
    "\n",
    "        minio_context_source = MinioContextSource(endpoint_url='http://minio-service.kubeflow.svc.cluster.local:9000', \n",
    "                                                  minio_secret='minio', \n",
    "                                                  minio_secret_key='minio123', \n",
    "                                                  region_name='us-east-1')\n",
    "        builder = ClusterBuilder(\n",
    "            registry=DOCKER_REGISTRY,\n",
    "            image_name=image_name,\n",
    "            base_image=base_image,\n",
    "            context_source=minio_context_source,\n",
    "            push=True,\n",
    "            preprocessor=ConvertNotebookPreprocessor(\n",
    "                notebook_file=\"KFServing-fairing.ipynb\"\n",
    "            )\n",
    "        )\n",
    "        builder.build()       \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        serving = KFServing()\n",
    "        serving.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "brightfly/kubeflow-jupyter-lab:tf2.0-gpu",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
